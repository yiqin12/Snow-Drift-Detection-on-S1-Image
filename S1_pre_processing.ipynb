{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b149752-b598-4fe4-995c-ae93028d27d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Programming\\Anaconda3\\envs\\snap_esa-env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys #check the current environment\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d791fa-61de-4a1c-b1a4-1e3c30ef6b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mModules imported done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# MODULE                                # DESCRIPTION\n",
    "import os\n",
    "from os.path import join                # data access in file manager  \n",
    "from glob import iglob                  # data access in file manager\n",
    "import subprocess                       # external calls to system\n",
    "\n",
    "import esa_snappy                       # SNAP python interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745211ee-fef7-4aab-b04e-766f41582318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output directory\n",
    "output_dir = r\"E:\\MA_thesis\\Processed_Data\\S1_AtkaBay_2022_sigma0_dB\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb861e3-99c2-46a8-8d0c-49652d40000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read Sentinel-1 Products\n",
    "\n",
    "# Set target folder and extract metadata\n",
    "product_path = r\"F:\\Snow_Drift_Thesis\\Data\\SAR_Atka Bay\\S1_2022_Atka\"\n",
    "input_S1_files = sorted(list(iglob(join(product_path, '**', '*S1*.zip'), recursive=True)))\n",
    "\n",
    "s1_src_all = []  #create a list to store all raw S1 data\n",
    "file_name = []\n",
    "file_date =[]\n",
    "\n",
    "for i, file_path in enumerate(input_S1_files):\n",
    "    try:\n",
    "        print(f\" → read {i+1}/{len(input_S1_files)} scene: {os.path.basename(file_path)}\")\n",
    "        s1_src = esa_snappy.ProductIO.readProduct(file_path)  \n",
    "        s1_src_all.append(s1_src)   # save all files into a list\n",
    "        file_name.append(s1_src.getName())\n",
    "\n",
    "        date_str = os.path.basename(file_path).split('_')[4][:8]\n",
    "        file_date.append(date_str)\n",
    "\n",
    "        print(f\"  read successfully - size: {s1_src.getSceneRasterWidth()} x {s1_src.getSceneRasterHeight()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  read failure: {str(e)}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ad220-53f0-4daf-b18b-8263f3b60a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call gpt -h from command line， -h: help\n",
    "print(subprocess.Popen(['gpt','-h'], stdout=subprocess.PIPE, universal_newlines=True).communicate()[0])\n",
    "\n",
    "#set a function to get gpt help\n",
    "def get_gpt_help(operator):\n",
    "    result = subprocess.run(\n",
    "        ['gpt', '-h', operator],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        return result.stdout\n",
    "    else:\n",
    "        return f\"error：{result.stderr}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2201811-8b25-442d-8035-9eae8f1f1eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_gpt_help() testing\n",
    "# print(get_gpt_help('Write'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c579d2-c95f-4357-a79e-ccd1c339f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pbar = tqdm(zip(s1_src_all, file_name, file_date), total=len(s1_src_all))\n",
    "\n",
    "for s1_src, name, date in pbar:\n",
    "    # Update progress bar description: Display the name of the image currently being processed\n",
    "    pbar.set_description(f\"processing {name}\")\n",
    "\n",
    "# for s1_src, name, date in zip(s1_src_all, file_name, file_date):\n",
    "\n",
    "    ### Step 1: Apply Orbit File\n",
    "    # Parameter settings\n",
    "    parameters1 = esa_snappy.HashMap()\n",
    "    parameters1.put('orbitType', 'Sentinel Precise (Auto Download)')\n",
    "    parameters1.put('continueOnFail', True)\n",
    "\n",
    "    tem = esa_snappy.GPF.createProduct('Apply-Orbit-File', parameters1, s1_src)\n",
    "\n",
    "    \n",
    "    ### Step 2: Thermal Noise Removal\n",
    "    # Parameter settings\n",
    "    parameters2 = esa_snappy.HashMap()\n",
    "    parameters2.put('removeThermalNoise', True)\n",
    "    parameters2.put('selectedPolarisations', 'HH')\n",
    "\n",
    "    tem = esa_snappy.GPF.createProduct('ThermalNoiseRemoval', parameters2, tem)\n",
    "\n",
    "\n",
    "    ### Step 3: Radiometric Calibration\n",
    "    # Parameter settings\n",
    "    parameters3 = esa_snappy.HashMap()\n",
    "    parameters3.put('selectedPolarisations', 'HH')\n",
    "    parameters3.put('outputImageScaleInDb', False)\n",
    "    parameters3.put('outputSigmaBand', True)\n",
    "\n",
    "    tem = esa_snappy.GPF.createProduct(\"Calibration\", parameters3, tem)\n",
    "\n",
    "    \n",
    "    ### Step 4: Speckle Flitering\n",
    "    # Parameter settings\n",
    "    parameters4 = esa_snappy.HashMap()\n",
    "    parameters4.put('filter', 'Refined Lee')\n",
    "\n",
    "    tem = esa_snappy.GPF.createProduct('Speckle-Filter', parameters4, tem)\n",
    "\n",
    "    \n",
    "    ### Step 5: Terrain Correction\n",
    "    # Parameter settings\n",
    "    proj = '''PROJCS[\"WGS 84 / Antarctic Polar Stereographic\", \n",
    "      GEOGCS[\"WGS 84\", \n",
    "        DATUM[\"World Geodetic System 1984\", \n",
    "          SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], \n",
    "          AUTHORITY[\"EPSG\",\"6326\"]], \n",
    "        PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], \n",
    "        UNIT[\"degree\", 0.017453292519943295], \n",
    "        AXIS[\"Geodetic longitude\", EAST], \n",
    "        AXIS[\"Geodetic latitude\", NORTH], \n",
    "        AUTHORITY[\"EPSG\",\"4326\"]], \n",
    "      PROJECTION[\"Polar Stereographic (variant B)\", AUTHORITY[\"EPSG\",\"9829\"]], \n",
    "      PARAMETER[\"central_meridian\", 0.0], \n",
    "      PARAMETER[\"Standard_Parallel_1\", -71.0], \n",
    "      PARAMETER[\"false_easting\", 0.0], \n",
    "      PARAMETER[\"false_northing\", 0.0], \n",
    "      UNIT[\"m\", 1.0], \n",
    "      AXIS[\"Easting\", \"North along 90 deg East\"], \n",
    "      AXIS[\"Northing\", \"North along 0 deg\"], \n",
    "      AUTHORITY[\"EPSG\",\"3031\"]]'''\n",
    "\n",
    "    parameters5 = esa_snappy.HashMap()\n",
    "    parameters5.put('sourceBands', 'Sigma0_HH')\n",
    "    parameters5.put('demName', 'GETASSE30')\n",
    "    parameters5.put('imgResamplingMethod', 'BILINEAR_INTERPOLATION')\n",
    "    parameters5.put('mapProjection', proj)\n",
    "\n",
    "    tem = esa_snappy.GPF.createProduct('Terrain-Correction', parameters5, tem)\n",
    "\n",
    "    \n",
    "    ### Step 6： Convert sigma nought to dB\n",
    "    # Parameter settings\n",
    "    parameters6 = esa_snappy.HashMap()\n",
    "\n",
    "    tem = esa_snappy.GPF.createProduct('LinearToFromdB', parameters6, tem)\n",
    "\n",
    "    \n",
    "    ### Step 7: Subset: zoom to the study area Atka Bay\n",
    "    # Parameter settings\n",
    "    wkt_polygon = \"POLYGON((-8.2 -70.7, -7.4 -70.7, -7.4 -70.5, -8.2 -70.5, -8.2 -70.7))\"\n",
    "\n",
    "    parameters7 = esa_snappy.HashMap()\n",
    "    parameters7.put('copyMetadata', True)\n",
    "    parameters7.put('geoRegion', wkt_polygon)\n",
    "    parameters7.put('fullSwath', False)\n",
    "\n",
    "    tem = esa_snappy.GPF.createProduct('Subset', parameters7, tem)\n",
    "\n",
    "\n",
    "    ### Step 8: Write the pre-processed well products for Atka Bay\n",
    "    output_filename = f\"S1_AtkaBay_{date}_HH_sigma0_dB.tif\" \n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    esa_snappy.ProductIO.writeProduct(tem, output_path, 'GeoTIFF')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
